{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spoken GAN\n",
    "\n",
    "### A Generative Adversarial Network (GAN) for Spoken Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE SPOKEN DIGIT DATASET\n",
    "\n",
    "!git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET FILE NAMES OF SAMPLES\n",
    "\n",
    "from os import listdir, getcwd\n",
    "from os.path import isfile, join\n",
    "\n",
    "data_dir = join(getcwd(), 'free-spoken-digit-dataset', 'recordings')\n",
    "\n",
    "file_names = [f for f in listdir(data_dir) if f[-4:] == '.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DATA, PAD IT, ARRANGE INTO TENSOR\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "wavs = []\n",
    "for f in file_names:\n",
    "    _, wav = wavfile.read(join(data_dir, f))\n",
    "    wavs.append(wav)\n",
    "    \n",
    "max_length = max([w.shape[0] for w in wavs])\n",
    "# padded_length is least multiple of 128 greater\n",
    "# than 512 containing max_length\n",
    "padded_length = -128 * (-max_length // 128)\n",
    "\n",
    "\n",
    "padded_wavs = []\n",
    "for wav in wavs:\n",
    "    pad_size = padded_length - wav.shape[0]\n",
    "    left_pad = pad_size // 2\n",
    "    right_pad = pad_size - left_pad\n",
    "    padded_wavs.append(np.pad(wav, (left_pad, right_pad), mode='constant'))\n",
    "    \n",
    "X = np.stack(padded_wavs, axis=0)\n",
    "Y = np.array([[int(f[:1]),] for f in file_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "BUFFER_SIZE = X.shape[0]\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "def speak(sample):\n",
    "    return Audio(sample, rate=8000, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InverseSTFTLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, frame_length, frame_step):\n",
    "        super(InverseSTFTLayer, self).__init__()\n",
    "        self.frame_length = frame_length\n",
    "        self.frame_step = frame_step\n",
    "        #self.num_frames = 1 + (num_outputs - frame_length) // frame_step\n",
    "        #self.input_shape = (self.num_frames, 1 + frame_length // 2)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num_frames = input_shape[0]\n",
    "        self.num_outputs = self.frame_length + (self.num_frames - 1) * self.frame_step\n",
    "\n",
    "    def call(self, input):\n",
    "        inverse_stft = tf.signal.inverse_stft(\n",
    "            input, self.frame_length, self.frame_step,\n",
    "            window_fn=tf.signal.inverse_stft_window_fn(self.frame_step)\n",
    "        )\n",
    "        return inverse_stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length = 512\n",
    "frame_step = 128\n",
    "\n",
    "l = InverseSTFTLayer(frame_length, frame_step)\n",
    "\n",
    "waveform = tf.random.normal(dtype=tf.float32, shape=[padded_length])\n",
    "stft = tf.signal.stft(waveform, frame_length, frame_step, pad_end=False)\n",
    "output = l(stft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([140, 257])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length = 512\n",
    "frame_step = 128\n",
    "waveform = tf.random.normal(dtype=tf.float32, shape=[4096])\n",
    "stft = tf.signal.stft(waveform, frame_length, frame_step, pad_end=False)\n",
    "inverse_stft = tf.signal.inverse_stft(\n",
    "    stft, frame_length, frame_step,\n",
    "    window_fn=tf.signal.inverse_stft_window_fn(frame_step)\n",
    ")\n",
    "output = tf.where(tf.math.is_nan(inverse_stft), tf.zeros_like(inverse_stft), inverse_stft)\n",
    "\n",
    "speak(waveform - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speak(tf.pad(inverse_stft, tf.constant([[0,1024 - inverse_stft.shape[0]]]))[1:] - waveform[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(32, (5,5), strides=(2,2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 32)\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
